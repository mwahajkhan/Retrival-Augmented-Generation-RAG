{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13484.99s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.venv/lib/python3.9/site-packages (0.2.8)\n",
      "Requirement already satisfied: langchain_openai in ./.venv/lib/python3.9/site-packages (0.1.16)\n",
      "Requirement already satisfied: langchain_community in ./.venv/lib/python3.9/site-packages (0.2.7)\n",
      "Requirement already satisfied: pypdf in ./.venv/lib/python3.9/site-packages (4.3.0)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.9/site-packages (1.10.2)\n",
      "Requirement already satisfied: docarray in ./.venv/lib/python3.9/site-packages (0.20.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.9/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.9/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.9/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.9/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.19 in ./.venv/lib/python3.9/site-packages (from langchain) (0.2.20)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.9/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.9/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.venv/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.9/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.9/site-packages (from langchain) (0.1.87)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.32.0 in ./.venv/lib/python3.9/site-packages (from langchain_openai) (1.35.14)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.9/site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.9/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in ./.venv/lib/python3.9/site-packages (from pypdf) (4.12.2)\n",
      "Requirement already satisfied: jina-hubble-sdk>=0.24.0 in ./.venv/lib/python3.9/site-packages (from docarray) (0.39.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in ./.venv/lib/python3.9/site-packages (from docarray) (13.7.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (3.15.4)\n",
      "Requirement already satisfied: python-jose in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (3.3.0)\n",
      "Requirement already satisfied: importlib-metadata in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (8.0.0)\n",
      "Requirement already satisfied: pathspec in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (0.12.1)\n",
      "Requirement already satisfied: docker in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (7.1.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (24.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.19->langchain) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (2024.7.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.9/site-packages (from rich>=12.0.0->docarray) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.9/site-packages (from rich>=12.0.0->docarray) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->docarray) (0.1.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.9/site-packages (from importlib-metadata->jina-hubble-sdk>=0.24.0->docarray) (3.19.2)\n",
      "Requirement already satisfied: rsa in ./.venv/lib/python3.9/site-packages (from python-jose->jina-hubble-sdk>=0.24.0->docarray) (4.9)\n",
      "Requirement already satisfied: ecdsa!=0.15 in ./.venv/lib/python3.9/site-packages (from python-jose->jina-hubble-sdk>=0.24.0->docarray) (0.19.0)\n",
      "Requirement already satisfied: pyasn1 in ./.venv/lib/python3.9/site-packages (from python-jose->jina-hubble-sdk>=0.24.0->docarray) (0.6.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.9/site-packages (from ecdsa!=0.15->python-jose->jina-hubble-sdk>=0.24.0->docarray) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Users/khan/Desktop/Gen-AI/local-model/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain langchain_openai langchain_community pypdf pydantic docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13005.72s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docarray in ./.venv/lib/python3.9/site-packages (0.20.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from docarray) (1.26.4)\n",
      "Requirement already satisfied: jina-hubble-sdk>=0.24.0 in ./.venv/lib/python3.9/site-packages (from docarray) (0.39.0)\n",
      "Requirement already satisfied: rich>=12.0.0 in ./.venv/lib/python3.9/site-packages (from docarray) (13.7.1)\n",
      "Requirement already satisfied: docker in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (7.1.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (2.32.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (3.15.4)\n",
      "Requirement already satisfied: pathspec in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (0.12.1)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (3.9.5)\n",
      "Requirement already satisfied: python-jose in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (3.3.0)\n",
      "Requirement already satisfied: importlib-metadata in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (8.0.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.9/site-packages (from jina-hubble-sdk>=0.24.0->docarray) (6.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.9/site-packages (from rich>=12.0.0->docarray) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.9/site-packages (from rich>=12.0.0->docarray) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->docarray) (0.1.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.9/site-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.9/site-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.9/site-packages (from aiohttp->jina-hubble-sdk>=0.24.0->docarray) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.9/site-packages (from yarl<2.0,>=1.0->aiohttp->jina-hubble-sdk>=0.24.0->docarray) (3.7)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./.venv/lib/python3.9/site-packages (from docker->jina-hubble-sdk>=0.24.0->docarray) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests->jina-hubble-sdk>=0.24.0->docarray) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests->jina-hubble-sdk>=0.24.0->docarray) (2024.7.4)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.venv/lib/python3.9/site-packages (from importlib-metadata->jina-hubble-sdk>=0.24.0->docarray) (3.19.2)\n",
      "Requirement already satisfied: rsa in ./.venv/lib/python3.9/site-packages (from python-jose->jina-hubble-sdk>=0.24.0->docarray) (4.9)\n",
      "Requirement already satisfied: pyasn1 in ./.venv/lib/python3.9/site-packages (from python-jose->jina-hubble-sdk>=0.24.0->docarray) (0.6.0)\n",
      "Requirement already satisfied: ecdsa!=0.15 in ./.venv/lib/python3.9/site-packages (from python-jose->jina-hubble-sdk>=0.24.0->docarray) (0.19.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.9/site-packages (from ecdsa!=0.15->python-jose->jina-hubble-sdk>=0.24.0->docarray) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Users/khan/Desktop/Gen-AI/local-model/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install docarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lines import necessary modules and load environment variables from a .env file into the script. This is useful for securely managing sensitive information like API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPEN_API_KEY\")\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "#MODEL = \"mixtral\"\n",
    "MODEL = \"llama2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script retrieves the OpenAI API key from the environment variables and sets the model to be used. The initial model is set to \"gpt-3.5-turbo\", but it can be commented out and replaced with \"llama2\" depending on usage. Chatgpt turbo 3 is used to refrence the output with llama2 model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure! Here's one for you:\\n\\nWhy did the scarecrow win an award?\\n\\nBecause he was outstanding in his field!\", response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 11, 'total_tokens': 36}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-858efe90-2f31-40f5-a319-e57e46a0822d-0', usage_metadata={'input_tokens': 11, 'output_tokens': 25, 'total_tokens': 36})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Invoking GPT model\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(api_key=OPEN_API_KEY, model=MODEL)\n",
    "model.invoke(\"Tell a joke?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms? Because they make up everything!\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Invoking llama2 model\n",
    "#Embedding the question from user\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "if MODEL.startswith(\"gpt\"):\n",
    "    model = ChatOpenAI(api_key=OPENAI_API_KEY, model=MODEL)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "else:\n",
    "    model = Ollama(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings()\n",
    "\n",
    "model.invoke(\"Give a joke\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now adding a StrOutParser to convert AImessage into a string, in the langchain chain, and pipe the output as input of next component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code imports StrOutputParser, which is used to convert the model's output into a string. It then pipes the output of the model through the parser and invokes the chain with the prompt \"Tell me a joke?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWhy was the math book sad? Because it had too many problems! 😂'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser\n",
    "\n",
    "chain.invoke(\"Tell me a joke?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part imports PyPDFLoader to load and split a PDF file into individual pages. TheAny given pdf file \"path/to/pdf\" is loaded and split into pages, which are stored in the pages variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'mlschool-test.pdf', 'page': 0}, page_content='Building Machine Learning Systems That Don\\'t Suck\\nA live, interactive program that\\'ll help you build production-readymachine learning\\nsystems from the ground up.\\nNext cohort:\\xa0August5 - 22, 2024\\nCheck the schedulefor more details about upcoming cohorts.\\nI want to join!Sign in\\nLearn how to design, build, deploy, and scale machine learning\\nsystems to solve real-world problems.\\nI\\'ll lose my mind if I see another book or course teaching people the same basic ideas\\nfor the hundredth time. Most people are stuck in beginner mode, and finding help to\\nsolve real-world problems is hard.\\nI want to change that.\\nI started writing software 30 years ago. I\\'ve written pipelines and trained models for\\nsome of the largest companies in the world. I want to show you how to do the same.\\nThis is the class I wish I had taken when I started.\"This is the best machine learning course I\\'ve done.\\nWorth every cent.\"\\n— Jose Reyes, AI/ML at Cevo Australia7/16/24, 4:56 PM Building Machine Learning Systems That Don\\'t Suck\\nhttps://www.ml.school 1/10'),\n",
       " Document(metadata={'source': 'mlschool-test.pdf', 'page': 1}, page_content=\"This program will help you unlearn what you think machine learning is. It's a practical,\\nhands-on class where you'll learn from years of experience and real-world examples.\\nWhen you join, you get lifetime access to the following:\\n18 hours of live, interactive sessions. We'll use this time to discuss the first\\nprinciples behind building machine learning systems.\\n10 hours of step-by-step coding instructions. These practical sessions will show\\nyou how to build an end-to-end system from scratch.\\nA final project where you'll build a complete solution and receive direct\\nfeedback on your work.\\n100 coding assignments and practice questions.\\nThe entire source code of a working production system. It's yours. You can\\nchange and use it as you see fit.\\nA private community where you'll collaborate with thousands of people from\\ndifferent backgrounds.\\nDirect access to your instructor.\\nLifetime access to every past and future cohort.\\nProgram certificate upon completion.\\nAnd the best part is that you only pay once to join. There are no monthly fees. No\\nannual fees. No hidden costs. You pay once to join and benefit forever until the end of\\ntime.\\nThe program won't be easy. It'll take time and effort. But if you want to use machine\\nlearning to solve real-world problems,this is the class you don't want to miss.\\nWho Is This Program For?\\nThis is a practical, hands-on program for technical professionals who\\nare ready to put in the work.7/16/24, 4:56 PM Building Machine Learning Systems That Don't Suck\\nhttps://www.ml.school 2/10\"),\n",
       " Document(metadata={'source': 'mlschool-test.pdf', 'page': 2}, page_content='This program is for software engineers,data scientists,data analysts,machine\\nlearning engineers,technical managers, and anyone anyone who wants to use\\nmachine learning to solve real-world problems.\\nHere are the criteria to succeed in the program:\\nYou have experience writing code. We\\'ll use Python throughout the class, but\\nyou won\\'t have any problems if you know any other language.\\nYou are familiar with basic machine learning terminology. This is not an\\nintroductory class. We\\'ll move quickly over the basics to focus on the\\nfundamental ideas that make systems work.\\nYou are ready to put in the work to succeed.\\n\"I have learned a ton from Santiago in his class and it was actually what helped inspire me and\\nget into the MLOps work that I\\'m doing now. Truly one of the most helpful online courses for\\ndoing real, full-scale machine learning.\"\\nBrian H. Hough\\nSoftware Engineer\\nWhat Will You Learn?\\nYou\\'ll come out with practical skills and insights into what it takes to\\nbuild systems that work in the real world.\\nHere is a summary of what makes this program unique:7/16/24, 4:56 PM Building Machine Learning Systems That Don\\'t Suck\\nhttps://www.ml.school 3/10'),\n",
       " Document(metadata={'source': 'mlschool-test.pdf', 'page': 3}, page_content=\"You'll design and write the code to build an end-to-end machine learning\\nsystem starting from scratch.\\nYou'll learn best practices to tackle the most significant challenges machine\\nlearning engineers face to build, evaluate, run, monitor, and maintain machine\\nlearning systems in real-world scenarios.\\nYou'll learn how to use techniques like active learning, distributed training,\\nadversarial validation, human-in-the-loop deployments, model compression,\\ntest-time augmentation, testing in production, among many others.\\nYou'll learn how to create training, deploying, monitoring, and inference\\npipelines using Amazon SageMaker and open-source tools.\\nForget about theoretical concepts. This program will show you some of the things I've\\nlearned from real-life examples I've built during more than 30 years in the industry.\\nCheck the program syllabus\\xa0→\\nReal-life examples and case studies\\nLearn from practical experience building machine\\nlearning systems that work in the real world.\\nLive, interactive sessions\\nAsk questions and interact with the instructor and\\nother students in real time.\\n7/16/24, 4:56 PM Building Machine Learning Systems That Don't Suck\\nhttps://www.ml.school 4/10\"),\n",
       " Document(metadata={'source': 'mlschool-test.pdf', 'page': 4}, page_content=\"Code walkthroughs\\nStep by step coding instructions to help you build a\\nproduction system from scratch.\\nUpcoming Schedule\\nEvery iteration of the program gives you 18 hours of hands-on, live\\ntraining spread over 3 weeks.\\nHere are the upcoming cohorts:\\nCohort 15:August 5-August 22, 2024.10:00 AM EDT\\nLive sessions will take place every Monday and Thursday at the same time. On\\nWednesdays, we'll host office hours when you can bring your questions projects or\\nanything else you want to discuss.\\nMonday: Live session. 2 hours.\\nTuesday: Individual work.\\nWednesday: Optional office hours.\\nThursday: Live session. 2 hours.\\nFriday: Individual work.\\n7/16/24, 4:56 PM Building Machine Learning Systems That Don't Suck\\nhttps://www.ml.school 5/10\"),\n",
       " Document(metadata={'source': 'mlschool-test.pdf', 'page': 5}, page_content='Do not wait for a specific cohort to join the program. You have lifetime access to\\nevery past and future cohort, and the sooner you join, the more time you have to\\nprepare.\\nEvery session is recorded. You can attend live or watch the recorded version later.\\n\"This is one of the best classes I\\'ve ever purchased over the internet. Santiago is a terrific\\nteacher. The ability he has to share knowledge is fantastic. I recommend this course. Worth 10x\\nwhat he\\'s charging.\"\\nSal DiStefano\\nReady To Join The Program?\\nYou\\'ll get lifetime access. No monthly fees. No annual fees. No hidden\\ncosts.\\n$450\\nPay once. Access forever.\\nPay once to join the program and get lifetime access. You can participate in as many\\niterations as you\\'d like. No restrictions.7/16/24, 4:56 PM Building Machine Learning Systems That Don\\'t Suck\\nhttps://www.ml.school 6/10'),\n",
       " Document(metadata={'source': 'mlschool-test.pdf', 'page': 6}, page_content=\"Program Syllabus\\nThis program will teach you the practical skills and insights that will\\nhelp you build machine learning systems.\\nHere are the contents of the six live sessions of the program:\\nSession 1 - How To Start (Almost) Any Project\\nWhat makes production machine learning different from what you've learned.\\nThe strategy to solve the right problem using the right solution.\\nCritical questions to ask before starting any project.\\nProblem framing, inversion, and the haystack principle for building successful\\napplications.\\nThe first rule of machine learning engineering and how to start building.\\nData collection strategies. A technique to determine how much data you need.\\nThe problem of selection bias and how to deal with it.\\nLabeling data. Human annotations, natural labels and weak supervision.Join now\\nEnjoy 18 hours of live, interactive sessions\\nWatch 10 hours of step-by-step coding instructions\\nPractice with 100 coding assignments\\nAccess the complete source code of a production system\\nLearn how to start freelancing on Upwork\\nGet feedback and support from the community\\nGet direct feedback from your instructor7/16/24, 4:56 PM Building Machine Learning Systems That Don't Suck\\nhttps://www.ml.school 7/10\"),\n",
       " Document(metadata={'source': 'mlschool-test.pdf', 'page': 7}, page_content='Active learning using the uncertainty and diversity sampling strategies.\\nSession 2 - How to Build a Model\\nThe role of data cleaning and feature engineering to build better models.\\nTurning data into numbers using vectorization techniques.\\nProducing homogeneous features using normalization and standardization.\\nHandling and interpreting missing values using imputation techniques.\\nThe approach to choosing the best model to solve any problem.\\nRandom baselines and the zero-rule algorithm.\\nHow to use overfitting to build models that don\\'t suck.\\nHyperparameter tuning and experiment tracking.\\nMeasuring the quality of your holdout set.\\nAn introduction to distributed training using data parallelism and model\\nparallelism.\\nSee the remaining sessions\\n\"This is an awesome course! This is my second round and I continue learning. I recommend it\\nwith complete confidence.\"\\nJuan Olano\\nMachine Learning Engineer\\nFrequently Asked Questions7/16/24, 4:56 PM Building Machine Learning Systems That Don\\'t Suck\\nhttps://www.ml.school 8/10'),\n",
       " Document(metadata={'source': 'mlschool-test.pdf', 'page': 8}, page_content='If you can\\'t find the answer to your question, please reach out on\\nsocial media and I\\'ll be happy to help.\\nHow long will it take to complete the program?\\nIf you are attending the live sessions, you should set aside a minimum of 4 hours\\nevery week during the three weeks of the program. This commitment will be enough\\nfor engineer leaders or anyone not interested in the coding portion of the program.\\nThose interested in implementing the concepts discussed in class should set aside 2\\nto 4 hours weekly to complete the code walkthroughs and work on the assignments.\\nAre live sessions recorded?\\nYes, we record every live session. You can decide when to attend classes live or catch\\nup asynchronously later using the recording.\\nI\\'m a complete beginner. Is this program helpful for me?\\nThis program is not an introduction to machine learning.\\nWhile we\\'ll discuss many fundamental ideas behind machine learning, beginners will\\nfind the sessions go much faster than what\\'s optimal for them.\\nWhat does \"lifetime access\" mean?\\nYou only pay once to join the program and get immediate access to every past,\\npresent, and future cohort.\\nEvery new iteration of the program is better than the ones before. Many students take\\nclasses once and then join a later cohort to benefit from the updates.\\nThe lifetime access removes any pressure from having to complete the program when\\nlife gets in the way.7/16/24, 4:56 PM Building Machine Learning Systems That Don\\'t Suck\\nhttps://www.ml.school 9/10'),\n",
       " Document(metadata={'source': 'mlschool-test.pdf', 'page': 9}, page_content=\"Hey! I'm Santiago.\\nI'm the instructor of the program.\\nI'm a machine learning engineer with over two decades of experience\\nbuilding and scaling enterprise software and machine learning systems.\\nI love neural networks. I love to make them work at scale.\\nFrom 2009 to 2023, I built products for Disney, Boston Dynamics, IBM, Dell,\\nG4S, Anheuser-Busch, and NextEra Energy, among other clients. I learned\\nabout trade-offs and how to create products that work.\\nI started this program in March 2023. Since then, thousands of students\\nhave graduated, and I can't wait to meet you in class.\\nCopyright © 2024 Tideily LLC\\nAll rights reserved.7/16/24, 4:56 PM Building Machine Learning Systems That Don't Suck\\nhttps://www.ml.school 10/10\")]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loads a PDF file and splits it into pages using LangChain\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"mlschool-test.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating a prompt template to allow us to ask the model the question from pdf by providing specific context, this prompt Template takes in two parameters, {context}, and  {question}. Here {context} is the documents loaded in the doc loader, which will be stored in local vector store, and then passed into the chain as prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you can't \n",
      "answer the question, reply \"I don't know\".\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'OllamaInput',\n",
       " 'anyOf': [{'type': 'string'},\n",
       "  {'$ref': '#/definitions/StringPromptValue'},\n",
       "  {'$ref': '#/definitions/ChatPromptValueConcrete'},\n",
       "  {'type': 'array',\n",
       "   'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "     {'$ref': '#/definitions/HumanMessage'},\n",
       "     {'$ref': '#/definitions/ChatMessage'},\n",
       "     {'$ref': '#/definitions/SystemMessage'},\n",
       "     {'$ref': '#/definitions/FunctionMessage'},\n",
       "     {'$ref': '#/definitions/ToolMessage'}]}}],\n",
       " 'definitions': {'StringPromptValue': {'title': 'StringPromptValue',\n",
       "   'description': 'String prompt value.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'StringPromptValue',\n",
       "     'enum': ['StringPromptValue'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['text']},\n",
       "  'ToolCall': {'title': 'ToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'type': {'title': 'Type', 'enum': ['tool_call'], 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id']},\n",
       "  'InvalidToolCall': {'title': 'InvalidToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'error': {'title': 'Error', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'enum': ['invalid_tool_call'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error']},\n",
       "  'UsageMetadata': {'title': 'UsageMetadata',\n",
       "   'type': 'object',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens']},\n",
       "  'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'Message from an AI.\\n\\nAIMessage is returned from a chat model as a response to a prompt.\\n\\nThis message represents the output of the model and consists of both\\nthe raw output as returned by the model together standardized fields\\n(e.g., tool calls, usage metadata) added by the LangChain framework.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "    'tool_calls': {'title': 'Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/ToolCall'}},\n",
       "    'invalid_tool_calls': {'title': 'Invalid Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/InvalidToolCall'}},\n",
       "    'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'Message from a human.\\n\\nHumanMessages are messages that are passed in from a human to the model.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Instantiate a chat model and invoke it with the messages\\n        model = ...\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'Message for priming AI behavior.\\n\\nThe system message is usually passed in as the first of a sequence\\nof input messages.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import HumanMessage, SystemMessage\\n\\n        messages = [\\n            SystemMessage(\\n                content=\"You are a helpful assistant! Your name is Bob.\"\\n            ),\\n            HumanMessage(\\n                content=\"What is your name?\"\\n            )\\n        ]\\n\\n        # Define a chat model and invoke it with the messages\\n        print(model.invoke(messages))',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nFunctionMessage are an older version of the ToolMessage schema, and\\ndo not contain the tool_call_id field.\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.\\n\\nToolMessages contain the result of a tool invocation. Typically, the result\\nis encoded inside the `content` field.\\n\\nExample: A ToolMessage representing a result of 42 from a tool call with id\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        ToolMessage(content=\\'42\\', tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\')\\n\\n\\nExample: A ToolMessage where only part of the tool output is sent to the model\\n    and the full output is passed in to artifact.\\n\\n    .. versionadded:: 0.2.17\\n\\n    .. code-block:: python\\n\\n        from langchain_core.messages import ToolMessage\\n\\n        tool_output = {\\n            \"stdout\": \"From the graph we can see that the correlation between x and y is ...\",\\n            \"stderr\": None,\\n            \"artifacts\": {\"type\": \"image\", \"base64_data\": \"/9j/4gIcSU...\"},\\n        }\\n\\n        ToolMessage(\\n            content=tool_output[\"stdout\"],\\n            artifact=tool_output,\\n            tool_call_id=\\'call_Jja7J89XsjrOLA5r!MEOW!SL\\',\\n        )\\n\\nThe tool_call_id field is used to associate the tool call request with the\\ntool call response. This is useful in situations where a chat model is able\\nto request multiple tool calls in parallel.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'},\n",
       "    'artifact': {'title': 'Artifact'}},\n",
       "   'required': ['content', 'tool_call_id']},\n",
       "  'ChatPromptValueConcrete': {'title': 'ChatPromptValueConcrete',\n",
       "   'description': 'Chat prompt value which explicitly lists out the message types it accepts.\\nFor use in external schemas.',\n",
       "   'type': 'object',\n",
       "   'properties': {'messages': {'title': 'Messages',\n",
       "     'type': 'array',\n",
       "     'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "       {'$ref': '#/definitions/HumanMessage'},\n",
       "       {'$ref': '#/definitions/ChatMessage'},\n",
       "       {'$ref': '#/definitions/SystemMessage'},\n",
       "       {'$ref': '#/definitions/FunctionMessage'},\n",
       "       {'$ref': '#/definitions/ToolMessage'}]}},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ChatPromptValueConcrete',\n",
       "     'enum': ['ChatPromptValueConcrete'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['messages']}}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This {DocarrayInMemorySearch} is a local vector store opposed to pinecone which has a cloud storage. We are making vecrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13605.39s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docarray in ./.venv/lib/python3.9/site-packages (0.20.0)\n",
      "Collecting docarray\n",
      "  Using cached docarray-0.40.0-py3-none-any.whl (270 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./.venv/lib/python3.9/site-packages (from docarray) (1.26.4)\n",
      "Requirement already satisfied: types-requests>=2.28.11.6 in ./.venv/lib/python3.9/site-packages (from docarray) (2.32.0.20240712)\n",
      "Collecting pydantic>=1.10.8\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.9/site-packages (from docarray) (0.9.0)\n",
      "Requirement already satisfied: orjson>=3.8.2 in ./.venv/lib/python3.9/site-packages (from docarray) (3.10.6)\n",
      "Requirement already satisfied: rich>=13.1.0 in ./.venv/lib/python3.9/site-packages (from docarray) (13.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.9/site-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.9/site-packages (from pydantic>=1.10.8->docarray) (4.12.2)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.9/site-packages (from pydantic>=1.10.8->docarray) (2.20.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.9/site-packages (from rich>=13.1.0->docarray) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.9/site-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n",
      "Requirement already satisfied: urllib3>=2 in ./.venv/lib/python3.9/site-packages (from types-requests>=2.28.11.6->docarray) (2.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.9/site-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
      "Installing collected packages: pydantic, docarray\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.2\n",
      "    Uninstalling pydantic-1.10.2:\n",
      "      Successfully uninstalled pydantic-1.10.2\n",
      "  Attempting uninstall: docarray\n",
      "    Found existing installation: docarray 0.20.0\n",
      "    Uninstalling docarray-0.20.0:\n",
      "      Successfully uninstalled docarray-0.20.0\n",
      "Successfully installed docarray-0.40.0 pydantic-2.8.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Users/khan/Desktop/Gen-AI/local-model/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U docarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13859.59s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docarray\n",
      "  Using cached docarray-0.40.0-py3-none-any.whl (270 kB)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.9/site-packages (from docarray) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./.venv/lib/python3.9/site-packages (from docarray) (1.26.4)\n",
      "Requirement already satisfied: orjson>=3.8.2 in ./.venv/lib/python3.9/site-packages (from docarray) (3.10.6)\n",
      "Requirement already satisfied: rich>=13.1.0 in ./.venv/lib/python3.9/site-packages (from docarray) (13.7.1)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in ./.venv/lib/python3.9/site-packages (from docarray) (2.8.2)\n",
      "Requirement already satisfied: types-requests>=2.28.11.6 in ./.venv/lib/python3.9/site-packages (from docarray) (2.32.0.20240712)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.9/site-packages (from pydantic>=1.10.8->docarray) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.9/site-packages (from pydantic>=1.10.8->docarray) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.9/site-packages (from pydantic>=1.10.8->docarray) (2.20.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.9/site-packages (from rich>=13.1.0->docarray) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.9/site-packages (from rich>=13.1.0->docarray) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n",
      "Requirement already satisfied: urllib3>=2 in ./.venv/lib/python3.9/site-packages (from types-requests>=2.28.11.6->docarray) (2.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.9/site-packages (from typing-inspect>=0.8.0->docarray) (1.0.0)\n",
      "Installing collected packages: docarray\n",
      "Successfully installed docarray-0.40.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the '/Users/khan/Desktop/Gen-AI/local-model/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U docarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import docarray python package. Please install it with `pip install docarray`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Gen-AI/local-model/.venv/lib/python3.9/site-packages/langchain_community/vectorstores/docarray/base.py:23\u001b[0m, in \u001b[0;36m_check_docarray_import\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(da_version[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mint\u001b[39m(da_version[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m31\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use the DocArrayHnswSearch VectorStore the docarray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion >=0.32.0 is expected, received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocarray\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo upgrade, please run: `pip install -U docarray`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: To use the DocArrayHnswSearch VectorStore the docarray version >=0.32.0 is expected, received: 0.20.0.To upgrade, please run: `pip install -U docarray`.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocArrayInMemorySearch\n\u001b[0;32m----> 3\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mDocArrayInMemorySearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Gen-AI/local-model/.venv/lib/python3.9/site-packages/langchain_core/vectorstores/base.py:1058\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m   1057\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m-> 1058\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Gen-AI/local-model/.venv/lib/python3.9/site-packages/langchain_community/vectorstores/docarray/in_memory.py:69\u001b[0m, in \u001b[0;36mDocArrayInMemorySearch.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     54\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DocArrayInMemorySearch:\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an DocArrayInMemorySearch store and insert data.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m        DocArrayInMemorySearch Vector Store\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     store\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m store\n",
      "File \u001b[0;32m~/Desktop/Gen-AI/local-model/.venv/lib/python3.9/site-packages/langchain_community/vectorstores/docarray/in_memory.py:40\u001b[0m, in \u001b[0;36mDocArrayInMemorySearch.from_params\u001b[0;34m(cls, embedding, metric, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_params\u001b[39m(\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     30\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DocArrayInMemorySearch:\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize DocArrayInMemorySearch store.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m        **kwargs: Other keyword arguments to be passed to the get_doc_cls method.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[43m_check_docarray_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdocarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindex\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InMemoryExactNNIndex\n\u001b[1;32m     43\u001b[0m     doc_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_doc_cls(space\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/Gen-AI/local-model/.venv/lib/python3.9/site-packages/langchain_community/vectorstores/docarray/base.py:29\u001b[0m, in \u001b[0;36m_check_docarray_import\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     24\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use the DocArrayHnswSearch VectorStore the docarray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion >=0.32.0 is expected, received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocarray\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo upgrade, please run: `pip install -U docarray`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import docarray python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install docarray`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import docarray python package. Please install it with `pip install docarray`."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(\n",
    "    pages, \n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
